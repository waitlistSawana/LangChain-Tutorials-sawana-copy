{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sugarforever/LangChain-Tutorials/blob/main/LangChain_PDF_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "该Python notebook利用langchain的QA chain，结合Chroma来实现PDF文档Analysis-and-Comparison-between-Optimism-and-StarkNet.pdf的语义化搜索。\n",
        "\n",
        "该PDF文档共61页。通过本notebook，我们演示该字数规模的文件的语义化索引的OpenAI API开销。\n",
        "\n",
        "使用时，在本地创建`.env`，并如`.env.example`所示，设置有效的OpenAI API Key即可。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Nifwi9FrKb3g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ϵͳ�Ҳ���ָ����·����\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ϵͳ�Ҳ���ָ����·����\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ϵͳ�Ҳ���ָ����·����\n"
          ]
        }
      ],
      "source": [
        "%pip install openai > /dev/null\n",
        "%pip install chromadb > /dev/null\n",
        "%pip install langchain > /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5xgbUBve0LuN"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'typing_extensions'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdocument_loaders\u001b[39;00m \u001b[39mimport\u001b[39;00m PyMuPDFLoader\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\langchain\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mimportlib\u001b[39;00m \u001b[39mimport\u001b[39;00m metadata\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Optional\n\u001b[1;32m----> 6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m \u001b[39mimport\u001b[39;00m MRKLChain, ReActChain, SelfAskWithSearchChain\n\u001b[0;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcache\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseCache\n\u001b[0;32m      8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchains\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      9\u001b[0m     ConversationChain,\n\u001b[0;32m     10\u001b[0m     LLMBashChain,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     VectorDBQAWithSourcesChain,\n\u001b[0;32m     19\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\langchain\\agents\\__init__.py:2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m\"\"\"Interface for agents.\"\"\"\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      3\u001b[0m     Agent,\n\u001b[0;32m      4\u001b[0m     AgentExecutor,\n\u001b[0;32m      5\u001b[0m     AgentOutputParser,\n\u001b[0;32m      6\u001b[0m     BaseMultiActionAgent,\n\u001b[0;32m      7\u001b[0m     BaseSingleActionAgent,\n\u001b[0;32m      8\u001b[0m     LLMSingleActionAgent,\n\u001b[0;32m      9\u001b[0m )\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_iterator\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentExecutorIterator\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_toolkits\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m     12\u001b[0m     create_csv_agent,\n\u001b[0;32m     13\u001b[0m     create_json_agent,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     23\u001b[0m     create_xorbits_agent,\n\u001b[0;32m     24\u001b[0m )\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\langchain\\agents\\agent.py:13\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any, Callable, Dict, List, Optional, Sequence, Tuple, Union\n\u001b[0;32m     12\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39myaml\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic\u001b[39;00m \u001b[39mimport\u001b[39;00m BaseModel, root_validator\n\u001b[0;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_iterator\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentExecutorIterator\n\u001b[0;32m     16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mlangchain\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magents\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39magent_types\u001b[39;00m \u001b[39mimport\u001b[39;00m AgentType\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\pydantic\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpydantic_core\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      5\u001b[0m     FieldSerializationInfo,\n\u001b[0;32m      6\u001b[0m     FieldValidationInfo,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     10\u001b[0m     ValidatorFunctionWrapHandler,\n\u001b[0;32m     11\u001b[0m )\n\u001b[0;32m     13\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dataclasses\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\pydantic_core\\__init__.py:27\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Any \u001b[39mas\u001b[39;00m _Any\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_pydantic_core\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      7\u001b[0m     ArgsKwargs,\n\u001b[0;32m      8\u001b[0m     MultiHostUrl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     25\u001b[0m     to_jsonable_python,\n\u001b[0;32m     26\u001b[0m )\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcore_schema\u001b[39;00m \u001b[39mimport\u001b[39;00m CoreConfig, CoreSchema, CoreSchemaType, ErrorType\n\u001b[0;32m     29\u001b[0m \u001b[39mif\u001b[39;00m _sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[0;32m     30\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m NotRequired \u001b[39mas\u001b[39;00m _NotRequired\n",
            "File \u001b[1;32md:\\anaconda3\\lib\\site-packages\\pydantic_core\\core_schema.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING, Any, Callable, Dict, Hashable, List, Optional, Set, Type, Union\n\u001b[0;32m     13\u001b[0m \u001b[39mif\u001b[39;00m sys\u001b[39m.\u001b[39mversion_info \u001b[39m<\u001b[39m (\u001b[39m3\u001b[39m, \u001b[39m11\u001b[39m):\n\u001b[1;32m---> 14\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping_extensions\u001b[39;00m \u001b[39mimport\u001b[39;00m Protocol, Required, TypeAlias\n\u001b[0;32m     15\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     16\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m Protocol, Required, TypeAlias\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'typing_extensions'"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyMuPDFLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "UpOBdhBrdaiU"
      },
      "outputs": [],
      "source": [
        "PDF_NAME='Analysis-and-Comparison-between-Optimism-and-StarkNet.pdf'\n",
        "def load_pdf():\n",
        "  return PyMuPDFLoader(PDF_NAME).load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "_-1itVpTY8Gz"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'PyMuPDFLoader' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m docs \u001b[39m=\u001b[39m load_pdf()\n",
            "Cell \u001b[1;32mIn[11], line 3\u001b[0m, in \u001b[0;36mload_pdf\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_pdf\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m   \u001b[39mreturn\u001b[39;00m PyMuPDFLoader(PDF_NAME)\u001b[39m.\u001b[39mload()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'PyMuPDFLoader' is not defined"
          ]
        }
      ],
      "source": [
        "docs = load_pdf()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33zAThYjY9gA",
        "outputId": "bc6d338b-82e3-461f-be11-04b4f44af8fb"
      },
      "outputs": [],
      "source": [
        "print (f'You have {len(docs)} document(s) in your data')\n",
        "print (f'There are {len(docs[0].page_content)} characters in the first page of your document')\n",
        "\n",
        "total = 0\n",
        "for doc in docs:\n",
        "  total += len(doc.page_content)\n",
        "print (f'There are {total} characters in your document')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ziV20FzmZpm1"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "split_docs = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WlDqqN_6Z08T",
        "outputId": "c0f4d8f4-2840-41cf-c3fd-dd8da6b9a9fa"
      },
      "outputs": [],
      "source": [
        "print (f'Now you have {len(split_docs)} documents')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6IOlsXpbaIAw"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "import os\n",
        "\n",
        "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bE-KtYTCgkLw"
      },
      "outputs": [],
      "source": [
        "embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hGdpt9LygkLy"
      },
      "outputs": [],
      "source": [
        "persist_directory = 'starknet'\n",
        "collection_name = 'starknet_index'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.callbacks import get_openai_callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mQJJ8HRaf0I",
        "outputId": "d9343337-2df2-49dd-84d3-ac354ee65b7c"
      },
      "outputs": [],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    vectorstore = Chroma.from_documents(split_docs, embeddings, collection_name=collection_name, persist_directory=persist_directory)\n",
        "    vectorstore.persist()\n",
        "    print(cb)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBAx1_X-beQp"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V8hds-zybhfc"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=OPENAI_API_KEY)\n",
        "\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# Load the vectorstore from disk\n",
        "vectordb = Chroma(collection_name=collection_name, persist_directory=persist_directory, embedding_function=embeddings)\n",
        "\n",
        "query = \"What is starknet?\"\n",
        "docs = vectorstore.similarity_search(query, 3, include_metadata=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(chain.document_prompt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K3SlreQ2haC4",
        "outputId": "417ebd17-6bd3-431f-8699-3b9e81cd8911"
      },
      "outputs": [],
      "source": [
        "for doc in docs:\n",
        "    print(doc.metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(chain.prompt_length(docs, question='What is starknet?'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdF03LqphOQY",
        "outputId": "bc596972-7e39-479a-a921-5b17204f4b7f"
      },
      "outputs": [],
      "source": [
        "with get_openai_callback() as cb:\n",
        "    print(chain.run(input_documents=docs, question=query))\n",
        "    print(cb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
